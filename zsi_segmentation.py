# -*- coding: utf-8 -*-
"""ZSI_Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dLF5rHc0wzDgFcu-W1wF4mUTBehdaYGi

-------------------------------------------------------
**Zero-shot Instance Segmentation**
-------------------------------------------------------

**CVPR2021 paper**

**Implemented on google colab by zahra heydari**
-------------------------------------------------------

**IPM**
"""

!nvidia-smi

"""# **Install Conda on Google Colab**"""

!wget -c https://repo.anaconda.com/miniconda/Miniconda3-py37_4.10.3-Linux-x86_64.sh
!chmod +x Miniconda3-py37_4.10.3-Linux-x86_64.sh
!bash ./Miniconda3-py37_4.10.3-Linux-x86_64.sh -b -f -p /usr/local
!conda install -q -y --prefix /usr/local python=3.7 ujson
import sys
sys.path.append('/usr/local/lib/python3.7/site-packages')
!conda update -n base -c defaults conda

"""# **Clone ZSI-Segmentation from my github**"""

!git clone https://github.com/ZahraHeydari95/ZSI_Segmentation.git

"""**Go to ZSI_Segmentation**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd ZSI_Segmentation
!ls

"""# **Install requirements**"""

!conda install pytorch=1.1.0 torchvision=0.3.0 cudatoolkit=10.0 -c pytorch

!pip --no-cache-dir install -r requirements.txt

!pip install cython

!pip install ipykernel

"""# **Setup**"""

!python setup.py develop

"""**Number of cuda device**"""

import torch
torch.cuda.device_count()

"""# **Dataset - MSCOCO-2014 dataset**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd data/coco
!ls

"""**annotations dataset**"""

from google.colab import drive
drive.mount('/content/drive')

!cp /content/drive/MyDrive/annotations.zip /content/ZSI_Segmentation/data/coco

!unzip annotations.zip

!rm -rf annotations.zip

"""**train dataset**"""

!wget http://images.cocodataset.org/zips/train2014.zip

!unzip train2014.zip

!rm -rf train2014.zip

"""**validation dataset**"""

!wget http://images.cocodataset.org/zips/val2014.zip

!unzip val2014.zip

!rm -rf val2014.zip

# Commented out IPython magic to ensure Python compatibility.
# %cd ..
# %cd ..

!pwd

"""# **Training**

**48/17 split**
"""

!chmod +x tools/dist_train.sh
!bash ./tools/dist_train.sh configs/zsi/48_17/train/zero-shot-mask-rcnn-BARPN-bbox_mask_sync_bg_decoder.py 1

"""# **Inference & Evaluate**"""

!mkdir checkpoints

"""* checkpoint for 12 epoch


"""

!cp /content/drive/MyDrive/ZSI_48_17.pth /content/ZSI_Segmentation/checkpoints

"""* checkpoint for 1 epoch - train with me"""

!cp -av /content/ZSI_Segmentation/work_dirs /content/drive/MyDrive/

!cp /content/drive/MyDrive/work_dirs/zsi/48_17/epoch_1.pth /content/ZSI_Segmentation/checkpoints

!cp /content/drive/MyDrive/work_dirs/zsi/48_17/latest.pth /content/ZSI_Segmentation/checkpoints

"""**ZSI task for 48/17 split:**

inference:

* checkpoint for 12 epoch
"""

!chmod +x tools/dist_test.sh
!bash ./tools/dist_test.sh configs/zsi/48_17/test/zsi/zero-shot-mask-rcnn-BARPN-bbox_mask_sync_bg_decoder.py /content/ZSI_Segmentation/checkpoints/ZSI_48_17.pth 1 --json_out results/zsi_48_17.json

"""* checkpoint for 1 epoch - train with me"""

!chmod +x tools/dist_test.sh
!bash ./tools/dist_test.sh configs/zsi/48_17/test/zsi/zero-shot-mask-rcnn-BARPN-bbox_mask_sync_bg_decoder.py /content/ZSI_Segmentation/checkpoints/epoch_1.pth 1 --json_out results/zsi_48_17_epoch1.json

"""evaluate:"""

!mkdir results

"""* checkpoint for 12 epoch

(bounding box)
"""

!python tools/zsi_coco_eval.py results/zsi_48_17.bbox.json --ann data/coco/annotations/instances_val2014_unseen_48_17.json

"""(Segmentation)"""

!python tools/zsi_coco_eval.py results/zsi_48_17.segm.json --ann data/coco/annotations/instances_val2014_unseen_48_17.json --types segm

"""* checkpoint for 1 epoch - train with me

(bounding box)
"""

!python tools/zsi_coco_eval.py results/zsi_48_17_epoch1.bbox.json --ann data/coco/annotations/instances_val2014_unseen_48_17.json

"""(Segmentation)"""

!python tools/zsi_coco_eval.py results/zsi_48_17_epoch1.segm.json --ann data/coco/annotations/instances_val2014_unseen_48_17.json --types segm

"""**GZSI task for 48/17 split:**

inference:

* checkpoint for 12 epoch
"""

!chmod +x tools/dist_test.sh
!bash ./tools/dist_test.sh configs/zsi/48_17/test/gzsi/zero-shot-mask-rcnn-BARPN-bbox_mask_sync_bg_decoder_gzsi.py checkpoints/ZSI_48_17.pth 1 --json_out results/gzsi_48_17.json

"""evaluate:

* checkpoint for 12 epoch
"""

!python tools/gzsi_coco_eval.py results/gzsi_48_17.bbox.json --ann data/coco/annotations/instances_val2014_gzsi_48_17.json --gzsi --num-seen-classes 48

!python tools/gzsi_coco_eval.py results/gzsi_48_17.segm.json --ann data/coco/annotations/instances_val2014_gzsi_48_17.json --gzsi --num-seen-classes 48 --types segm

"""# **Show instance Dataset**"""

import matplotlib.pyplot as plt
painting1=plt.imread("data/coco/val2014/COCO_val2014_000000285235.jpg")
painting2=plt.imread("data/coco/val2014/COCO_val2014_000000071667.jpg")

plt.subplot(2,1,1);
plt.imshow(painting1);


plt.subplot(2,1,2);
plt.imshow(painting2);

!python tools/test.py configs/zsi/48_17/test/zsi/zero-shot-mask-rcnn-BARPN-bbox_mask_sync_bg_decoder.py ./checkpoints/ZSI_48_17.pth --show

import json

bbox = []

with open('/content/ZSI_Segmentation/results/zsi_48_17.bbox.json') as f:
    text_bbox = f.read()
    bbox.append(json.loads(text_bbox))

segm = []

with open('/content/ZSI_Segmentation/results/zsi_48_17.segm.json') as f:
    text_segm = f.read()
    segm.append(json.loads(text_segm))

bbox[0][100]

segm[0][100]

x_bbox = bbox[0][100].get("bbox")
x_category_id = bbox[0][100].get("category_id")
x_image_id = bbox[0][100].get("image_id")
x_score = bbox[0][100].get("score")
x_segmentation = segm[0][100].get("segmentation")
x_size = segm[0][100].get("size")

x_image_id

x_bbox

import random

import cv2
from matplotlib import pyplot as plt

import albumentations as A

BOX_COLOR = (255, 0, 0) # Red
TEXT_COLOR = (255, 255, 255) # White


def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):
    """Visualizes a single bounding box on the image"""
    x_min, y_min, w, h = bbox
    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)
   
    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)
    
    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    
    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)
    cv2.putText(
        img,
        text=class_name,
        org=(x_min, y_min - int(0.3 * text_height)),
        fontFace=cv2.FONT_HERSHEY_SIMPLEX,
        fontScale=0.35, 
        color=TEXT_COLOR, 
        lineType=cv2.LINE_AA,
    )
    return img


def visualize(image, bboxes, category_ids, category_id_to_name):
    img = image.copy()
    for bbox, category_id in zip(bboxes, category_ids):
        class_name = category_id_to_name[category_id]
        img = visualize_bbox(img, bbox, class_name)
    plt.figure(figsize=(12, 12))
    plt.axis('off')
    plt.imshow(img)

image = cv2.imread('data/coco/val2014/COCO_val2014_000000143931.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

bboxes = [x_bbox]
category_ids = [x_category_id]

# We will use the mapping from category_id to the class name
# to visualize the class label for the bounding box on the image
category_id_to_name = {x_category_id: 'unseen'}

visualize(image, bboxes, category_ids, category_id_to_name)